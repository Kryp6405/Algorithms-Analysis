{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Karatsuba's Multiplication</b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Version Time Complexity\n",
    "$$\n",
    "\n",
    "$$\n",
    "Two-Digit Multiplication: \n",
    "$\n",
    "\\left\\{\\begin{aligned}\n",
    "    AB &= (10A_1+A_0)(10B_1+B_0)\\\\\n",
    "    &= 100A_1B_1+10(A_1B_0 + A_0B_1)+A_0B_0\\\\\n",
    "    &= 100A_1B_1+10(A_1B_0 + A_0B_1 + A_0B_0 + A_1B_1 - A_0B_0 - A_1B_1)+A_0B_0\\\\\n",
    "    &= 100A_1B_1+10((A_1+A_0)B_0 + (A_1+A_0)B_1 - A_0B_0 - A_1B_1)+A_0B_0\\\\\n",
    "    &= 100A_1B_1+10((A_1+A_0)(B_0 + B_1) - A_0B_0 - A_1B_1)+A_0B_0\\\\\n",
    "    &= 100k_1+10(k_2-k_1-k_3)+k_3\\\\\n",
    "\\end{aligned}\\right.\n",
    "$\n",
    "$$\n",
    "\n",
    "$$\n",
    "Generalized Multiplication: \n",
    "$\n",
    "    AB = 10^nk_1+10^{n/2}(k_2-k_1-k_3)+k_3\\\\\n",
    "$\n",
    "$$\n",
    "\n",
    "$$\n",
    "Master Theorem: \n",
    "$\n",
    "\\left\\{\\begin{aligned}\n",
    "    T(n) &= 3T(n/2) + \\Theta(n) \\rightarrow\\\\\n",
    "    c=1 &\\text{ \\& } a=3, b=2, \\log_ba = \\log_23 > 1 \\rightarrow \\operatorname{Case}\\ 1\\\\\n",
    "    T(n) &= \\boxed{\\Theta(n^{\\lg 3})}\\\\\n",
    "\\end{aligned}\\right.\n",
    "$\n",
    "$$\n",
    "\n",
    "$$\n",
    "$\n",
    "\\begin{aligned}\n",
    "    \\text{Best Case: }&\\Omega(1)\\\\\n",
    "    \\text{Avg. Case: }&\\Theta(n^{\\lg3}) \\\\\n",
    "    \\text{Worst Case: }&O(n^{\\lg3}) \\\\\n",
    "\\end{aligned}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def num_of_digits(x):\n",
    "    if x == 0:\n",
    "        return 1  \n",
    "    \n",
    "    count = 0\n",
    "    while x > 0:\n",
    "        count += 1\n",
    "        x //= 10\n",
    "    \n",
    "    return count\n",
    "\n",
    "def karatsuba(A, B):\n",
    "    if num_of_digits(A) <= 1 or num_of_digits(B) <= 1: # base case: A or B is a single digit\n",
    "        return A * B\n",
    "\n",
    "    n = max(num_of_digits(A), num_of_digits(B)) // 2 \n",
    "    split_point = 10 ** n\n",
    "    A1, A0 = A // split_point, A % split_point\n",
    "    B1, B0 = B // split_point, B % split_point\n",
    "\n",
    "    k1 = karatsuba(A1, B1) # runs in T(n/2)\n",
    "    k2 = karatsuba(A1 + A0, B1 + B0) # runs in T(n/2)\n",
    "    k3 = karatsuba(A0, B0) # runs in T(n/2)\n",
    "\n",
    "    return (10 ** (2 * n) * k1) + (10 ** n * (k2 - k1 - k3)) + (k3) # decimal shifts and addition runs in O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For this topic, know all the basics. Understand the underlying equation and why it is the way it\n",
    "is. Understand what problem we’re trying to solve, etc.</p>\n",
    "<ul>\n",
    "    <li>The algorithim proposes a mroe efficient way of doing integer multiplication problem through a divide and conquer approach.\n",
    "    <li>By rewriting the second multiplication term using two values we already know, we reduce a set of extra multiplications, hence the recursive approach.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Huffman Coding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know what it is, what it’s for, and its role in the broader CS context. Be able to create a tree given a string.\n",
    "1. What do we do with the encoding tree once we have it?\n",
    "    - The tree allows us to perform two main operations: Encoding & Decoding\n",
    "        - **Encoding Data**: Traverse the tree based on the data you want to compress.  For each symbol (letter, character) in the data, follow the path from the root node to the leaf node representing that symbol.  The path consists of a sequence of 0s (left branches) and 1s (right branches).  This sequence of 0s and 1s represents the compressed code for the symbol.\n",
    "        - **Decoding Data**: The receiver of the compressed data (the sequence of 0s and 1s) needs the Huffman tree to reconstruct the original data. Starting from the root node, follow the branches based on the received bits (0 for left, 1 for right).  When you reach a leaf node, that symbol is added to the decoded data.  Continue this process for the entire compressed bit sequence to reconstruct the original data. \n",
    "2. Does Huffman always produce the smallest encoding?\n",
    "    - No, as Huffman coding utilizes a **greedy algorithm** to construct the encoding tree, and this approach can lead to the possibility of not achieving the absolute optimal encoding in some cases. Here's why:\n",
    "        - Greedy Choice: The algorithm makes locally optimal decisions at each step. It chooses the two least frequent symbols to combine into a parent node, focusing on minimizing the immediate cost (combined symbol frequency).\n",
    "        - Global Impact Ignored:  While these choices seem efficient in the short term, they might not lead to the most efficient overall tree structure. The algorithm doesn't consider the impact of these choices on the lengths of codewords for other symbols later in the tree creation process.\n",
    "    - For example, if two symbols with slightly different frequencies are combined early, it might force longer codewords for more frequent symbols later on. A different combination strategy, considering the impact on the entire tree, could potentially lead to a more efficient encoding scheme.\n",
    "3. Does Huffman always produce a unique encoding?\n",
    "    - No. There may be trees (even single characters) with equal counts and there may be more than one way to pick two trees with minimum total count. \n",
    "        - Suppose we have \"ABABCDDC\" where all counts are 2. Two different possible encdoing trees can be:\n",
    "        ``` mermaid\n",
    "                 -:8                                 -:8                \n",
    "               /     \\                             /     \\\n",
    "            -:4      -:4           <=>           -:6     D:2 \n",
    "           /   \\    /   \\                       /   \\  \n",
    "         A:2  B:2  C:2  D:2                   -:4   C:2\n",
    "                                              /  \\\n",
    "                                            A:2  B:2\n",
    "        ``` \n",
    "    - Moreover when we combine two trees to form a new tree it doesn’t really matter which goes left and which goes right, meaning which gets assigned a branch value of 0 and which gets assigned a branch value of 1.\n",
    "        - Suppose we have \"ABBCCCDDDD\". Two different possible encdoing trees can be:\n",
    "        ``` mermaid\n",
    "                 -:10                                -:10                \n",
    "                /     \\                             /     \\\n",
    "              D:4     -:6           <=>           -:6     D:4 \n",
    "                     /   \\                       /   \\  \n",
    "                   -:3   C:3                   -:3   C:3\n",
    "                   /  \\                        /  \\\n",
    "                 A:1  B:2                    A:1  B:2\n",
    "        ``` \n",
    "4. What is the difference between Huffman encoding and a fixed length code\n",
    "    - **Adaptability**\n",
    "      - Huffman approach is *adaptive*. It analyzes the data and assigns shorter codes to symbols that appear more frequently, resulting in more efficient compression for data with uneven symbol distribution.\n",
    "      - Fixed-Length approach is *non-adaptive*. Every symbol gets assigned a codeword of the same length, regardless of its frequency in the data. This can be inefficient for data with skewed symbol probabilities.\n",
    "    - **Code Length**\n",
    "      - Huffman codeword *lengths can vary* based on symbol frequency. Frequent symbols have shorter codes, while less frequent symbols have longer codes. This minimizes the overall number of bits needed to represent the data. \n",
    "      - Fixed-Length always yields codes with the *same length*, typically based on the number of unique symbols in the data. This approach can be simpler to implement but less efficient for data with uneven symbol distribution.\n",
    "    - **Compression Efficiency** \n",
    "      - Huffman generally achieves *better compression ratios*, especially for data with skewed symbol frequencies. By assigning shorter codes to frequent symbols, it reduces the overall number of bits needed to represent the data.\n",
    "      - Fixed-Length can *lead to wasted bits* if some symbols are much less frequent than others. Since all codes are the same length, it doesn't take advantage of the uneven symbol distribution to minimize data size.\n",
    "    - **Complexity**\n",
    "      - Huffman is slightly *more complex* to implement due to the need for creating/traversing tree based on symbol probabilities and usage of PQ/Heaps.\n",
    "      - Fixed-Length is *simpler* to implement as it doesn't require any tree structure. Just assign a fixed-length code to each symbol.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Minimax & Expectimax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand what minimax algorithm is, what it does, and why we use it.\n",
    "1. What is a heuristic, and why do we use it?\n",
    "    - **Rigorous Definition**: A heuristic is a problem-solving strategy or algorithm that aims to find approximate solutions or make decisions in a timely manner, often in situations where finding an optimal solution is computationally infeasible. \n",
    "    - **Dummy Definition**: A simpler way to think about a heuristic is as a rule of thumb or a shortcut used to make decisions or solve problems. It's a general approach that might not always be perfect, but it's good enough for most situations and helps us navigate complex problems with limited informatio\n",
    "2. Does having the perfect heuristic, $h*(s)$ guarantee victory?\n",
    "    - A **perfect heuristic**, in the context of problem solving and decision making, is a hypothetical function that always provides the optimal solution to a problem in a single step. It would essentially be a shortcut that cuts through all the complexity and instantly guides you to the best possible outcome.\n",
    "    - However, it **doesn't guarantee victory** in all situations due to factors like incomplete information, hidden costs, and the influence of external factors.\n",
    "    - Nevertheless, it would be a powerful tool for problem-solving and decision-making, minimizing effort and leading to consistent success in scenarios with complete information.\n",
    "3. How does minimax behave in probabilistic spaces? Try drawing a sample tree with chance nodes.\n",
    "    - Minimax struggles in probabilistic spaces, also known as stochastic games, because it assumes a worst-case scenario for the opponent. In these environments, where chance plays a role, the minimax approach might not be the most effective strategy. \n",
    "        - Instead, in stochastic games defined in probablistic spaces, the Expectimax algorithm recognizes chance nodes where the outcome depends on probabilities.\n",
    "        - Averaging Expected Values: At chance nodes, Expectimax calculates the expected value for the maximizing player by averaging the outcome values for each possible chance event, weighted by their probabilities.\n",
    "4. Is the minimax algorithm optimal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **P vs NP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand what P and NP are. You’ll also need to know what a reduction is. You maybe be asked to perform a simple one (not nearly as intense as what we did in class). It’s also possible you’ll be asked to reproduce what we did in class, or explain how they worked. You should know what a decision problem is.\n",
    "1. How do you show something is in P?\n",
    "    - You need to design a deterministic algorithm that solves the problem in polynomial time. \n",
    "    - Analyze the number of steps the algorithm takes as the input size increases. \n",
    "    - If the number of steps can be expressed as a polynomial function of the input size, then the problem is in P.\n",
    "2. How do you show something is in NP?\n",
    "    - You need to show two things:\n",
    "        - There exists a verification algorithm that can check a solution to the problem in polynomial time.\n",
    "        - The problem itself is a decision problem (has a yes/no answer).\n",
    "3. Can you show that something is in P and not in NP?\n",
    "    \n",
    "4. Can you reduce an NP Complete problem to something in P?\n",
    "5. Name three NP-Complete problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
